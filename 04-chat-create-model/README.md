# Use the Ollama Chat API with models

> run the demos:
```bash
node no-stream.mjs
node stream.mjs
```

ðŸ‘‹ the notion of model seems to have no real impact with `tinydolphin`, to be tested with another LLM